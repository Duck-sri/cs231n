{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a348f80-14cd-4b7b-8e9c-3d8c75e0c77a",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fe164614-df75-4fbc-9d77-c54b7f73d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from typing import List,Dict,Optional,Union,Tuple,Any,Iterable\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm,trange\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d70a4612-7390-471d-8f34-4a6fe120a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(func):\n",
    "    \n",
    "    def wrapped_func(*args,**kwargs):\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        res = func(*args,**kwargs)\n",
    "        end = time.perf_counter()\n",
    "        \n",
    "        print(f\"{func.__name__} took {(end-start):>1f}s to run\")\n",
    "    \n",
    "    return wrapped_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa0acd-b1e9-49a9-a66a-03a178fd7ad7",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Loading the Data\n",
    "\n",
    "### CIFAR 10\n",
    "\n",
    "    Image classification dataset with 10 classes\n",
    "    \n",
    "    Classes : 10\n",
    "    Train   : 50,000\n",
    "    Test    : 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c95761-f142-4644-b112-7d6e0b563cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10(Dataset):\n",
    "    \n",
    "    def __init__(self,data_dir:str,train:bool=True,transform=None,label_transform=None):\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        self.Xs = np.array([])\n",
    "        self.ys = np.array([])\n",
    "        self.names = {}\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.label_transform = label_transform\n",
    "\n",
    "        self.label_names = {  \n",
    "            0: \"airplane\",\n",
    "            1: \"automobile\",\n",
    "            2: \"bird\",\n",
    "            3: \"cat\",\n",
    "            4: \"deer\",\n",
    "            5: \"dog\",\n",
    "            6: \"frog\",\n",
    "            7: \"horse\",\n",
    "            8: \"ship\" ,\n",
    "            9: \"truck\",\n",
    "        }\n",
    "        \n",
    "        def filename_to_name_idx(name):\n",
    "            name = str(name).split('_')\n",
    "            return name[-1],name[0]\n",
    "        \n",
    "        if train:\n",
    "            files = filter(lambda file: 'data' in file, os.listdir(self.data_dir))\n",
    "        else:\n",
    "            files = filter(lambda file: 'test' in file, os.listdir(self.data_dir))\n",
    "\n",
    "        count = 0\n",
    "        for file in files:\n",
    "            data,labels,names = self.unpickle(os.path.join(self.data_dir,file))\n",
    "            if count == 0:\n",
    "                self.Xs = np.array(data)\n",
    "                self.ys = np.array(labels)\n",
    "                count += 1\n",
    "            else:\n",
    "                self.Xs = np.vstack((self.Xs,data))\n",
    "                self.ys = np.vstack((self.ys,labels))\n",
    "\n",
    "            names = {idx:name for idx,name in map(filename_to_name_idx,names)}\n",
    "\n",
    "            self.names.update(names)\n",
    "        \n",
    "        self.ys = self.ys.reshape(-1)\n",
    "        assert self.Xs.shape[0]==self.ys.shape[0],f\"Data and labels are not in same shape {self.Xs.shape,self.ys.shape}\"\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self.Xs.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx) -> Tuple[np.ndarray,Union[int,np.ndarray]]:\n",
    "        image = self.Xs[idx]\n",
    "        label = self.ys[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.label_transform:\n",
    "            label = self.label_transform(label)\n",
    "        \n",
    "        return image,label\n",
    "    \n",
    "    def show_example(self,idx:int) -> None:\n",
    "        img,label = self.__getitem__(idx)\n",
    "        plt.imshow(img.transpose(1,2,0))\n",
    "        plt.title(self.label_names[label])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    def show_random_example(self) -> None:\n",
    "        idx = np.random.randint(0,self.__len__())\n",
    "        self.show_example(idx)\n",
    "        \n",
    "    def get_random_grid(self,grid_size:int = 5,viz:bool=False) -> np.ndarray:\n",
    "        \n",
    "        idx = lambda : np.random.randint(0,len(self))\n",
    "        img = np.concatenate([ np.concatenate( [ self[idx()][0].transpose(1,2,0) for _ in range(grid_size)] ,axis=1) for _ in range(grid_size) ],axis=0)\n",
    "        if viz:\n",
    "            fig = plt.figure(figsize=(7,7))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            return img\n",
    "            \n",
    "    @staticmethod\n",
    "    def unpickle(filename:str) -> Any:\n",
    "        with open(filename,'rb') as file:\n",
    "            batch = pickle.load(file,encoding='bytes')\n",
    "        \n",
    "        try:\n",
    "            labels = batch[b'labels']\n",
    "            data = batch[b'data'].reshape(-1,3,32,32)\n",
    "            names = batch[b'filenames']\n",
    "        except:\n",
    "            print(type(batch))\n",
    "        \n",
    "        return data,labels,names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a71c5e5-db52-4035-82f3-927b9e2d6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/cifar-10-batches-py/')\n",
    "files = os.listdir(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c2c6b-56cb-4832-b175-27aef095197f",
   "metadata": {},
   "source": [
    "#### Train/Val/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b54d6676-59bc-475c-a6f9-02496ef17a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Cifar10(data_dir)\n",
    "ds_test = Cifar10(data_dir,train=False)\n",
    "\n",
    "split = 0.9\n",
    "train_set,val_set = torch.utils.data.random_split(\n",
    "    ds_train,\n",
    "    ( int(len(ds_train)*(split)) , int(len(ds_train)*(1-split)) + 1 )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f028cae-20b7-4156-8624-2eaaf7e1a98e",
   "metadata": {},
   "source": [
    "#### Using Pytorch Dataset and Dataloader for ease access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11ec632b-12b8-4771-bdc1-e6845207a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bs = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=Bs,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=Bs,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=ds_test,\n",
    "    batch_size=Bs,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a2b7f-27f3-4875-bc29-1ea71fa6fa7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification\n",
    "\n",
    "### k-NN classification\n",
    "    \n",
    "- Categorize all the training examples\n",
    "- While Predicting -> find $k$ nearest neighours and return common class of the neighbours\n",
    "    \n",
    "#### Metrics\n",
    "\n",
    "##### L1 distance\n",
    "    Manhattan Distance\n",
    "    Used where individual elements makes meaning like (emp salary, age, etc)\n",
    "    \n",
    "$$ L_{1} = \\sum_{i=i}^{n}|{x_{i}}| $$ \n",
    "\n",
    "##### L2 distance (np default) \n",
    "    Forebinus norm, Euclid Distance\n",
    "    \n",
    "$$ L_{2} = \\sqrt{\\sum_{i=i}^{n}{|{x_{i}}|}^2} = \\|x\\|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "477bed7f-0ca5-4b74-af9e-ba5fd56fd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \n",
    "    def __init__(self,dataset):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.Xs,self.ys = self.dataset[:]\n",
    "    \n",
    "    def forward(self):\n",
    "        # Just memorizing all the data\n",
    "        pass\n",
    "        \n",
    "    def predict(self,img,metric:bool='l2',k:int=1,viz:bool=False):\n",
    "        \n",
    "        # ineffective\n",
    "        if metric == 'l1':\n",
    "            distances = np.sum(np.abs((X - img).reshape(X.shape[0],-1)),axis=-1)\n",
    "        elif metric=='l2':\n",
    "            distances = np.linalg.norm((X - img).reshape(X.shape[0],-1)**2,axis=-1)\n",
    "            \n",
    "        if k > 1:\n",
    "            nearest_k = (-distances).argsort()[:n]\n",
    "            nearest = nearest_k[0]\n",
    "        else:\n",
    "            nearest = distances.argmin(axis=0)\n",
    "            pred = self.ys[nearest]\n",
    "        \n",
    "        if viz:\n",
    "            fig,ax = plt.subplots(nrows=1,ncols=2,figsize=(7,7))\n",
    "            ax[0].imshow(self.Xs[nearest].transpose(1,2,0))\n",
    "            ax[0].set_title(self.ys[nearest])\n",
    "            ax[1].imshow(img.transpose(1,2,0))\n",
    "            ax[1].set_title(f\"Pred as :{self.ys[nearest]}\")\n",
    "            plt.show()\n",
    "            \n",
    "        return self.ys[nearest]\n",
    "    \n",
    "    @timeit\n",
    "    def test(self,size:int=1000):\n",
    "        \n",
    "        crct = 0\n",
    "        \n",
    "        # very ineffective cause for every n test example it has to find diff for M train examples\n",
    "        for idx in np.random.randint(0,len(knn.dataset),(size)):\n",
    "            img,label = knn.dataset[idx]\n",
    "            aug_x = img + np.random.randint(0,150,(3,32,32))\n",
    "            aug_x = 255 * (aug_x - aug_x.min())/(aug_x.max()-aug_x.min())\n",
    "            \n",
    "            res = self.predict(np.int32(aug_x),metric='l1')\n",
    "            crct += int(res == label)\n",
    "        \n",
    "        print(f\"Acc : {crct/size *100}% for size {size}\")\n",
    "        \n",
    "knn = KNN(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdaa7b-7463-4d7f-8ec6-906d2af8dd43",
   "metadata": {},
   "source": [
    "#### Test Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c8086fec-ff64-414c-8663-cf492170b100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 70.0% for size 10\n",
      "test took 4.595266s to run\n"
     ]
    }
   ],
   "source": [
    "knn.test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ded5e-d6a7-438c-a284-2b18847c2895",
   "metadata": {},
   "source": [
    "### Linear\n",
    "\n",
    "#### Parametric model\n",
    "- Find a meaningful function h (linear)\n",
    "- Find the best fiting $\\theta$ for the given train set $X$\n",
    "$$ \\hat{y} = h(X,\\theta) $$\n",
    "- Define the Loss func $J$ such that the goal is\n",
    "$$ \\underset{\\theta}{argmin}\\ {J(X,\\theta)} $$\n",
    "- Traning with convex optimization $\\eta$ is learning_rate\n",
    "$$ \\theta\\ \\leftarrow\\ \\theta - \\eta.{J'(X,\\theta))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e1edc-6cc9-4faf-ad59-7bc95a567501",
   "metadata": {},
   "source": [
    "#### Linear Layer\n",
    "\n",
    "- Notation\n",
    "    \n",
    "    - No. Example : $m,i$\n",
    "    - No. feature : $n,j$\n",
    "    - Input       : $X \\in {\\mathbb{R^{n*m}}}$\n",
    "    - Label       : $y \\in {\\mathbb{R^{k}}}$ $k$ classes\n",
    "    - Prediction  : $\\hat{y}$\n",
    "    - Weights.    : $\\theta \\in {\\mathbb{R^{n*k}}}$\n",
    "    - Biases.     : $b \\in {\\mathbb{R^{n*1}}}$\n",
    "    - Loss fn     : $J$\n",
    "    - L.Rate      : $\\eta$\n",
    "- hypothesis is kinda a straight line eqation\n",
    "$$ h(X,\\theta,b) = \\theta^TX\\ + b = \\hat{y}$$\n",
    "- Loss function is MSE  where $\\lambda$ is regularization\n",
    "$$ J(y,\\hat{y}) = \\frac{1}{2m}\\sum_{i=1}^{m}\\sum_{j=1}^{n}{(y_{j}^{(i)}-\\hat{y}_{j}^{(i)})}^2 + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}(\\theta_j)^2$$\n",
    "- Optimization : SGD\n",
    "$$ \\theta_j \\leftarrow \\theta_j - \\eta.{J'(y,\\hat{y})_\\theta}$$\n",
    "$$ b_j \\leftarrow b_j - \\eta.{J'(y,\\hat{y})_b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a30c4b-f4a9-428d-ae8d-361a72a43c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
